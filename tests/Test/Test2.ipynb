{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:51:56.658747Z",
     "start_time": "2024-09-17T14:51:56.644280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import Strategy\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
   ],
   "id": "989186a86524f740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.11.1 / PyTorch 2.4.1+cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading Data\n",
   "id": "7256f2642b7ea18c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:52:28.263422Z",
     "start_time": "2024-09-17T14:52:28.254361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_datasets(partition_id, num_partitions: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
    "        # we will use this function to dataset.with_transform(apply_transforms)\n",
    "        # The transforms object is exactly the same\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloader, valloader, testloader"
   ],
   "id": "800eda8a6bdaf13",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training/Evaluation",
   "id": "c6ed2d1f78818e4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:52:39.565289Z",
     "start_time": "2024-09-17T14:52:39.546650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"], batch[\"label\"]\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ],
   "id": "609e45606562dc1a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Flower Client",
   "id": "8dc655d97ab49390"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:52:53.247621Z",
     "start_time": "2024-09-17T14:52:53.232262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ],
   "id": "d7113599f4441077",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T14:57:15.653913Z",
     "start_time": "2024-09-17T14:53:10.948283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_PARTITIONS = 10\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Configure the server for just 3 rounds of training\n",
    "    config = ServerConfig(num_rounds=3)\n",
    "    # If no strategy is provided, by default, ServerAppComponents will use FedAvg\n",
    "    return ServerAppComponents(config=config)\n",
    "\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "# Specify the resources each of your clients need\n",
    "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": None}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ],
   "id": "6f6de2474f4e3f07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Requesting initial parameters from one random client\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\utils\\_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m [Client 3] get_parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Received initial parameters from one random client\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n",
      "\u001B[92mINFO \u001B[0m:      Evaluation returned no results (`None`)\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m Epoch 1: train loss 0.06410486251115799, accuracy 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\utils\\_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\utils\\_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 3] fit, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m Epoch 1: train loss 0.06512409448623657, accuracy 0.233\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m [Client 5] fit, config: {}\u001B[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m Epoch 1: train loss 0.06465844064950943, accuracy 0.23875\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m [Client 9] fit, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m Epoch 1: train loss 0.0641520768404007, accuracy 0.2485\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[93mWARNING \u001B[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 2] evaluate, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m Epoch 1: train loss 0.06427044421434402, accuracy 0.23425\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 5] evaluate, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m [Client 9] evaluate, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[93mWARNING \u001B[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 3] fit, config: {}\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 8] evaluate, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m Epoch 1: train loss 0.05616927519440651, accuracy 0.3405\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 4] fit, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m Epoch 1: train loss 0.05750694498419762, accuracy 0.31775\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 9] fit, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m Epoch 1: train loss 0.05651210993528366, accuracy 0.33625\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m [Client 2] evaluate, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 8] fit, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m Epoch 1: train loss 0.05710785835981369, accuracy 0.32625\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m [Client 4] evaluate, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m [Client 8] evaluate, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 3]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 9] evaluate, config: {}\n",
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m Epoch 1: train loss 0.05363813415169716, accuracy 0.35925\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 4] fit, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m Epoch 1: train loss 0.053426772356033325, accuracy 0.3695\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 7] fit, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=6360)\u001B[0m Epoch 1: train loss 0.05277547240257263, accuracy 0.3725\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=972)\u001B[0m [Client 3] evaluate, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m [Client 9] fit, config: {}\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m Epoch 1: train loss 0.05291402339935303, accuracy 0.37825\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 6] evaluate, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=14040)\u001B[0m [Client 9] evaluate, config: {}\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 3 round(s) in 213.28s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.061414684236049656\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 0.05465796995162964\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 3: 0.05185622270107269\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m [Client 8] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\utils\\_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "\u001B[36m(ClientAppActor pid=14820)\u001B[0m   obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Strategy Customization\n",
    "\n",
    "## Server-side parameter initialization\n",
    "\n",
    "Flower, by default, initializes the global model by asking one random client for the initial parameters. In many cases, we want more control over parameter initialization though. Flower therefore allows you to directly pass the initial parameters to the Strategy. We create an instance of Net() and get the paramaters as follows:"
   ],
   "id": "bd54b58ab775bf45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53946eb082394df6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
